{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalabframework as dlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/src'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.project.rootpath()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine = dlf.engines.get('spark')\n",
    "spark = engine.context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark:2.3.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out name and version\n",
    "'{}:{}'.format(engine.info['context'], spark.sparkSession.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT \n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def string_indexer(features):\n",
    "    for c in features:\n",
    "        yield StringIndexer(inputCol=c, outputCol=c+'_N')\n",
    "\n",
    "def onehot(features):\n",
    "    #todo: reproducable mapping, \n",
    "    #      here the mapping depends on the data provided\n",
    "    for c in features:\n",
    "        yield OneHotEncoder(inputCol=c, outputCol=c+'_C')\n",
    "\n",
    "def vectorize(stringCols, numericDiscreteCols, numericContinuosCols):\n",
    "    #todo: automatically classify columns\n",
    "    reg_all_discrete_cols = numericDiscreteCols + [c+'_N' for c in stringCols]\n",
    "    reg_all_cols = numericContinuosCols + [c+'_C' for c in reg_all_discrete_cols]\n",
    "\n",
    "    print(reg_all_cols)\n",
    "\n",
    "    si = list(string_indexer(reg_cat_string_cols))\n",
    "    oh = list(onehot(reg_cat_indexed_cols))\n",
    "    ar = [VectorAssembler(inputCols=reg_all_cols, outputCol=\"features\")]\n",
    "    \n",
    "    stages=si+oh+ar\n",
    "    return stages\n",
    "\n",
    "def featurize(df, idCol, labelCol, stringCols, numericDiscreteCols, numericContinuosCols):\n",
    "\n",
    "    #set the pipeline\n",
    "    stages = vectorize(stringCols, numericDiscreteCols, numericContinuosCols)\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    #fit\n",
    "    model = pipeline.fit(df)\n",
    "\n",
    "    #transform\n",
    "    features_df = model.transform(df).select(col(idCol).alias('id'), col(labelCol).alias('label'),'features')\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+------------------+-----+-----+-------+--------+------+\n",
      "|PassengerId|Survived|Pclass|   Sex|               Age|SibSp|Parch|   Fare|Embarked| Title|\n",
      "+-----------+--------+------+------+------------------+-----+-----+-------+--------+------+\n",
      "|          1|       0|     3|  male|              22.0|    1|    0|   7.25|       S|    Mr|\n",
      "|          2|       1|     1|female|              38.0|    1|    0|71.2833|       C|   Mrs|\n",
      "|          3|       1|     3|female|              26.0|    0|    0|  7.925|       S|  Miss|\n",
      "|          4|       1|     1|female|              35.0|    1|    0|   53.1|       S|   Mrs|\n",
      "|          5|       0|     3|  male|              35.0|    0|    0|   8.05|       S|    Mr|\n",
      "|          6|       0|     3|  male|29.128677373963985|    0|    0| 8.4583|       Q|    Mr|\n",
      "|          7|       0|     1|  male|              54.0|    0|    0|51.8625|       S|    Mr|\n",
      "|          8|       0|     3|  male|               2.0|    3|    1| 21.075|       S|Master|\n",
      "|          9|       1|     3|female|              27.0|    0|    2|11.1333|       S|   Mrs|\n",
      "|         10|       1|     2|female|              14.0|    1|    0|30.0708|       C|   Mrs|\n",
      "|         11|       1|     3|female|               4.0|    1|    1|   16.7|       S|  Miss|\n",
      "|         12|       1|     1|female|              58.0|    0|    0|  26.55|       S|  Miss|\n",
      "|         13|       0|     3|  male|              20.0|    0|    0|   8.05|       S|    Mr|\n",
      "|         14|       0|     3|  male|              39.0|    1|    5| 31.275|       S|    Mr|\n",
      "|         15|       0|     3|female|              14.0|    0|    0| 7.8542|       S|  Miss|\n",
      "|         16|       1|     2|female|              55.0|    0|    0|   16.0|       S|   Mrs|\n",
      "|         17|       0|     3|  male|               2.0|    4|    1| 29.125|       Q|Master|\n",
      "|         18|       1|     2|  male|29.227425180631577|    0|    0|   13.0|       S|    Mr|\n",
      "|         19|       0|     3|female|              31.0|    1|    0|   18.0|       S|   Mrs|\n",
      "|         20|       1|     3|female| 29.10186237738492|    0|    0|  7.225|       C|   Mrs|\n",
      "+-----------+--------+------+------+------------------+-----+-----+-------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = engine.read('.etl.clean.train')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0087e4c29f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'overwrite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/datalabframework/engines.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, obj, resource, **kargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/datalabframework/data.py\u001b[0m in \u001b[0;36mpath\u001b[0;34m(datasource)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'providers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'provider'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'service'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'fs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "engine.write(df,'train', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
