{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalabframework as dlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/natbusa/Projects/dsp-titanic/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.project.rootpath()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = dlf.engines.get('spark')\n",
    "spark = engine.context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark:2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out name and version\n",
    "'{}:{}'.format(engine.info['context'], spark.sparkSession.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = engine.read('.etl.features.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------------------------------------------------------------+\n",
      "|id |label|features                                                              |\n",
      "+---+-----+----------------------------------------------------------------------+\n",
      "|246|0    |(19,[0,1,3,6,10,16],[44.0,90.0,1.0,1.0,1.0,1.0])                      |\n",
      "|346|1    |(19,[0,1,4,10,17],[24.0,13.0,1.0,1.0,1.0])                            |\n",
      "|360|1    |(19,[0,1,2,4,10],[27.046921317757153,7.8792,1.0,1.0,1.0])             |\n",
      "|367|1    |(19,[0,1,3,5,10,18],[60.0,75.25,1.0,1.0,1.0,1.0])                     |\n",
      "|476|0    |(19,[0,1,3,4,10,16,17],[42.24366964356571,52.0,1.0,1.0,1.0,1.0,1.0])  |\n",
      "|539|0    |(19,[0,1,2,4,10,16,17],[28.93837380874933,14.5,1.0,1.0,1.0,1.0,1.0])  |\n",
      "|599|0    |(19,[0,1,2,4,10,16,18],[27.140094702369655,7.225,1.0,1.0,1.0,1.0,1.0])|\n",
      "|725|1    |(19,[0,1,3,5,10,16,17],[27.0,53.1,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|855|0    |(19,[0,1,5,10,17],[44.0,26.0,1.0,1.0,1.0])                            |\n",
      "|861|0    |(19,[0,1,2,6,10,16,17],[41.0,14.1083,1.0,1.0,1.0,1.0,1.0])            |\n",
      "|114|0    |(19,[0,1,2,5,10,17],[20.0,9.825,1.0,1.0,1.0,1.0])                     |\n",
      "|173|1    |(19,[0,1,2,5,11,17],[1.0,11.1333,1.0,1.0,1.0,1.0])                    |\n",
      "|220|0    |(19,[0,1,4,10,16,17],[30.0,10.5,1.0,1.0,1.0,1.0])                     |\n",
      "|278|0    |(19,[0,4,10,16,17],[33.06090664874488,1.0,1.0,1.0,1.0])               |\n",
      "|301|1    |(19,[0,1,2,4,10],[27.047467185239,7.75,1.0,1.0,1.0])                  |\n",
      "|494|0    |(19,[0,1,3,4,10,16,18],[71.0,49.5042,1.0,1.0,1.0,1.0,1.0])            |\n",
      "|669|0    |(19,[0,1,2,4,10,16,17],[43.0,8.05,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|713|1    |(19,[0,1,3,5,10,16,17],[48.0,52.0,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|810|1    |(19,[0,1,3,5,10,17],[33.0,53.1,1.0,1.0,1.0,1.0])                      |\n",
      "|813|0    |(19,[0,1,4,10,16,17],[35.0,10.5,1.0,1.0,1.0,1.0])                     |\n",
      "+---+-----+----------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "prediction = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'label', 'features', 'rawPrediction', 'probability', 'prediction']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------------------------------------+\n",
      "|label|prediction|probability                              |\n",
      "+-----+----------+-----------------------------------------+\n",
      "|0    |0.0       |[0.6338514343795529,0.36614856562044706] |\n",
      "|1    |1.0       |[0.16785546841435905,0.8321445315856411] |\n",
      "|1    |1.0       |[0.32706095199330093,0.6729390480066991] |\n",
      "|1    |1.0       |[0.14984516602550196,0.850154833974498]  |\n",
      "|0    |0.0       |[0.644949035890669,0.355050964109331]    |\n",
      "|0    |0.0       |[0.9136950493522981,0.08630495064770191] |\n",
      "|0    |0.0       |[0.8846879853377492,0.11531201466225084] |\n",
      "|1    |1.0       |[0.4826396805212696,0.5173603194787304]  |\n",
      "|0    |1.0       |[0.29084458841296656,0.7091554115870334] |\n",
      "|0    |0.0       |[0.9593691522270278,0.040630847772972094]|\n",
      "|0    |1.0       |[0.33015591727015353,0.6698440827298464] |\n",
      "|1    |1.0       |[0.14107916981588908,0.8589208301841109] |\n",
      "|0    |0.0       |[0.7870901345432633,0.21290986545673674] |\n",
      "|0    |0.0       |[0.8103448956650996,0.18965510433490043] |\n",
      "|1    |1.0       |[0.3271280477708435,0.6728719522291565]  |\n",
      "|0    |0.0       |[0.8145653966953992,0.1854346033046007]  |\n",
      "|0    |0.0       |[0.9494609226495201,0.050539077350479925]|\n",
      "|1    |0.0       |[0.6831679762941752,0.31683202370582475] |\n",
      "|1    |1.0       |[0.07621083240609325,0.9237891675939068] |\n",
      "|0    |0.0       |[0.8185248804827745,0.18147511951722553] |\n",
      "+-----+----------+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select('label', 'prediction','probability').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation areaUnderROC : 0.8636356373629883\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "metric = evaluator.evaluate(prediction)\n",
    "metric_name = evaluator.getMetricName()\n",
    "\n",
    "print(\"Evaluation {} : {}\".format(metric_name, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save(path='lr2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "m2 = PipelineModel.load(path='lr2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation areaUnderROC : 0.8636356373629885\n"
     ]
    }
   ],
   "source": [
    "prediction = m2.transform(df)\n",
    "metric = evaluator.evaluate(prediction)\n",
    "metric_name = evaluator.getMetricName()\n",
    "\n",
    "print(\"Evaluation {} : {}\".format(metric_name, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
