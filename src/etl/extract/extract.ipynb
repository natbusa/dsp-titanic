{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datalabframework as dlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/natbusa/Projects/dsp-titanic/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.project.rootpath()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'engines': {'spark': {'config': {'jobname': 'default', 'master': 'local[1]'},\n",
       "   'context': 'spark'}},\n",
       " 'loggers': {'kafka': {'enable': False,\n",
       "   'hosts': ['localhost:29092'],\n",
       "   'severity': 'info',\n",
       "   'topic': 'dlf'},\n",
       "  'stream': {'enable': True, 'severity': 'info'}},\n",
       " 'providers': {'local': {'rootpath': '../data', 'service': 'fs'}},\n",
       " 'resources': {'.etl.clean.test': {'format': 'parquet',\n",
       "   'path': 'datasets/clean/test',\n",
       "   'provider': 'local'},\n",
       "  '.etl.clean.train': {'format': 'parquet',\n",
       "   'path': 'datasets/clean/train',\n",
       "   'provider': 'local'},\n",
       "  '.etl.extract.test': {'format': 'parquet',\n",
       "   'path': 'datasets/extract/test',\n",
       "   'provider': 'local'},\n",
       "  '.etl.extract.train': {'format': 'parquet',\n",
       "   'path': 'datasets/extract/train',\n",
       "   'provider': 'local'},\n",
       "  '.etl.features.test': {'format': 'parquet',\n",
       "   'path': 'datasets/features/test',\n",
       "   'provider': 'local'},\n",
       "  '.etl.features.train': {'format': 'parquet',\n",
       "   'path': 'datasets/features/train',\n",
       "   'provider': 'local'},\n",
       "  '.etl.raw.test': {'format': 'csv',\n",
       "   'path': 'datasets/raw/test.csv',\n",
       "   'provider': 'local'},\n",
       "  '.etl.raw.train': {'format': 'csv',\n",
       "   'path': 'datasets/raw/train.csv',\n",
       "   'provider': 'local'}},\n",
       " 'run': 'default'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = dlf.params.metadata()\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine = dlf.engines.get('spark')\n",
    "spark = engine.context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark:2.3.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out name and version\n",
    "'{}:{}'.format(engine.info['context'], spark.sparkSession.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId  Integer    True\n",
      "Survived     Integer    True\n",
      "Pclass       Integer    True\n",
      "Name         String     True\n",
      "Sex          String     True\n",
      "Age          Double     True\n",
      "SibSp        Integer    True\n",
      "Parch        Integer    True\n",
      "Ticket       String     True\n",
      "Fare         Double     True\n",
      "Cabin        String     True\n",
      "Embarked     String     True\n"
     ]
    }
   ],
   "source": [
    "df = engine.read('.etl.raw.train', header=True, inferSchema=True)\n",
    "for column in df.schema:\n",
    "    print('{:<12} {:<10} {}'.format(column.name, str(column.dataType)[:-4], column.nullable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine.write(df, '.etl.extract.train', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Null or NaN values, and count them per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId  Integer    True\n",
      "Pclass       Integer    True\n",
      "Name         String     True\n",
      "Sex          String     True\n",
      "Age          Double     True\n",
      "SibSp        Integer    True\n",
      "Parch        Integer    True\n",
      "Ticket       String     True\n",
      "Fare         Double     True\n",
      "Cabin        String     True\n",
      "Embarked     String     True\n"
     ]
    }
   ],
   "source": [
    "df = engine.read('.etl.raw.test', header=True, inferSchema=True)\n",
    "for column in df.schema:\n",
    "    print('{:<12} {:<10} {}'.format(column.name, str(column.dataType)[:-4], column.nullable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine.write(df,'.etl.extract.test', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId  Integer    True\n",
      "Pclass       Integer    True\n",
      "Name         String     True\n",
      "Sex          String     True\n",
      "Age          Double     True\n",
      "SibSp        Integer    True\n",
      "Parch        Integer    True\n",
      "Ticket       String     True\n",
      "Fare         Double     True\n",
      "Cabin        String     True\n",
      "Embarked     String     True\n"
     ]
    }
   ],
   "source": [
    "for column in df.schema:\n",
    "    print('{:<12} {:<10} {}'.format(column.name, str(column.dataType)[:-4], column.nullable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Null or NaN values, and count them per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/natbusa/Projects/dsp-titanic/src/etl/features/features.ipynb\n"
     ]
    }
   ],
   "source": [
    "from etl.features.features import describe_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "|summary|       PassengerId|            Pclass|                Name|   Sex|               Age|             SibSp|             Parch|            Ticket|              Fare|Cabin|Embarked|\n",
      "+-------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "|  count|               418|               418|                 418|   418|               332|               418|               418|               418|               417|   91|     418|\n",
      "|   mean|            1100.5|2.2655502392344498|                null|  null|30.272590361445783|0.4473684210526316|0.3923444976076555|223850.98986486485|  35.6271884892086| null|    null|\n",
      "| stddev|120.81045760473994|0.8418375519640503|                null|  null|14.181209235624424|0.8967595611217135|0.9814288785371694| 369523.7764694362|55.907576179973844| null|    null|\n",
      "|    min|               892|                 1|\"Assaf Khalil, Mr...|female|              0.17|                 0|                 0|            110469|               0.0|  A11|       C|\n",
      "|    max|              1309|                 3|van Billiard, Mas...|  male|              76.0|                 8|                 9|       W.E.P. 5734|          512.3292|   G6|       S|\n",
      "+-------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+------+--------+\n",
      "| summary|       PassengerId|            Pclass|                Name|   Sex|               Age|             SibSp|             Parch|            Ticket|              Fare| Cabin|Embarked|\n",
      "+--------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+------+--------+\n",
      "|     nan|                 0|                 0|                   0|     0|                 0|                 0|                 0|                 0|                 0|     0|       0|\n",
      "|  isnull|                 0|                 0|                   0|     0|                86|                 0|                 0|                 0|                 1|   327|       0|\n",
      "|    type|           Integer|           Integer|              String|String|            Double|           Integer|           Integer|            String|            Double|String|  String|\n",
      "|distinct|               418|                 3|                 418|     2|                79|                 7|                 8|               363|               169|    76|       3|\n",
      "|   count|               418|               418|                 418|   418|               332|               418|               418|               418|               417|    91|     418|\n",
      "|    mean|            1100.5|2.2655502392344498|                None|  None|30.272590361445783|0.4473684210526316|0.3923444976076555|223850.98986486485|  35.6271884892086|  None|    None|\n",
      "|  stddev|120.81045760473994|0.8418375519640503|                None|  None|14.181209235624424|0.8967595611217135|0.9814288785371694| 369523.7764694362|55.907576179973844|  None|    None|\n",
      "|     min|               892|                 1|\"Assaf Khalil, Mr...|female|              0.17|                 0|                 0|            110469|               0.0|   A11|       C|\n",
      "|     max|              1309|                 3|van Billiard, Mas...|  male|              76.0|                 8|                 9|       W.E.P. 5734|          512.3292|    G6|       S|\n",
      "+--------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe_all(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
