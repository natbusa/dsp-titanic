{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalabframework as dlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/natbusa/Projects/dsp-titanic/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.project.rootpath()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine = dlf.engines.get('spark')\n",
    "spark = engine.context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark:2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out name and version\n",
    "'{}:{}'.format(engine.info['context'], spark.sparkSession.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT \n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import count, row_number, desc\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#create a lookup table from spark dataframe\n",
    "def collect_lut(df, discreteCols=[]):\n",
    "    lut = pd.DataFrame(columns=['name', 'value', 'count'])\n",
    "    for colname in discreteCols:\n",
    "        occurrences = df.groupBy(col(colname).alias('value')).agg(count(colname).alias('count')).sort('count', ascending=False)\n",
    "        rows = [row.asDict() for row in occurrences.collect()]\n",
    "        pdf = pd.DataFrame(rows, columns=['name','value', 'count'], dtype=object)\n",
    "        pdf['name'] = colname\n",
    "        pdf['count'].apply(np.int32)\n",
    "        pdf['value'] = pdf['value'].astype(str)\n",
    "        lut = lut.append(pdf)\n",
    "    d = spark.createDataFrame(lut)\n",
    "    d = d.withColumn(\"index\", row_number().over(Window.partitionBy(\"name\").orderBy(desc(\"count\"))) - 1 )\n",
    "    return d\n",
    "\n",
    "# # encoding columns\n",
    "# from pyspark import SparkContext\n",
    "# sc = SparkContext._active_spark_context\n",
    "\n",
    "# #reproducable labeling with default for unknown values\n",
    "# lutdf = lut.toPandas().set_index(['name','value'])[['index']]\n",
    "# b_lutdf = sc.broadcast(lutdf)\n",
    "\n",
    "# # Use pandas_udf to define a Pandas UDF\n",
    "# @pandas_udf('integer', PandasUDFType.SCALAR)\n",
    "# def encode_colum(v, c):\n",
    "#     d = b_lutdf.value.loc[c[0]]['index'].to_dict()\n",
    "#     r = v.apply(lambda x: d.get(str(x),0))\n",
    "#     return r\n",
    "\n",
    "# # cols = ['Sex','SibSp', 'Embarked']\n",
    "# # for c in cols:\n",
    "# #     df = df.withColumn(c+'_L', encode_colum(col(c), lit(c)))\n",
    "# # df.show()\n",
    "\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType, DoubleType\n",
    "\n",
    "class LookupIndexer(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None, lookupTable=None):\n",
    "        self.lookupTable = Param(self, \"lookupTable\", \"\")\n",
    "        self._setDefault(stopwords=set())\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None, lookupTable=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def setLookupTable(self, value):\n",
    "        self._paramMap[self.lookupTable] = value\n",
    "        return self\n",
    "\n",
    "    def getLookupTable(self):\n",
    "        return self.getOrDefault(self.lookupTable)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        lookupTable = self.getlookupTable()\n",
    "\n",
    "        #pandas utf goes here\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, lit(42))\n",
    "\n",
    "def lookup_indexer(features):\n",
    "    for c in features:\n",
    "        yield LookupIndexer(inputCol=c, outputCol=c+'_I')    \n",
    "\n",
    "def string_indexer(features):\n",
    "    for c in features:\n",
    "        yield StringIndexer(inputCol=c, outputCol=c+'_I')\n",
    "\n",
    "def onehot(features):\n",
    "    #todo: reproducable mapping, \n",
    "    #      here the mapping depends on the data provided\n",
    "    for c in features:\n",
    "        yield OneHotEncoder(inputCol=c, outputCol=c+'_C')\n",
    "\n",
    "def featurize(df, idCol=None, labelCol=None, numericContinuosCols=[], numericDiscreteCols=[], stringCols=[], lut=None):\n",
    "\n",
    "    #if lut available apply it first on the discrete columns\n",
    "    if lut:\n",
    "        # encoding columns\n",
    "        from pyspark import SparkContext\n",
    "        sc = SparkContext._active_spark_context\n",
    "\n",
    "        #reproducable labeling with default for unknown values\n",
    "        lutdf = lut.toPandas().set_index(['name','value'])[['index']]\n",
    "        b_lutdf = sc.broadcast(lutdf)\n",
    "\n",
    "        # Use pandas_udf to define a Pandas UDF\n",
    "        @pandas_udf('integer', PandasUDFType.SCALAR)\n",
    "        def encode_colum(v, c):\n",
    "            d = b_lutdf.value.loc[c[0]]['index'].to_dict()\n",
    "            r = v.apply(lambda x: d.get(str(x),0))\n",
    "            return r\n",
    "\n",
    "        for c in numericDiscreteCols+stringCols:\n",
    "            df = df.withColumn(c+'_I', encode_colum(col(c), lit(c)))\n",
    "\n",
    "        reg_all_discrete_cols = [c+'_I' for c in numericDiscreteCols+stringCols]\n",
    "        stages = []\n",
    "    else:\n",
    "        reg_all_discrete_cols = [c+'_I' for c in numericDiscreteCols+stringCols]\n",
    "        stages = list(lookup_indexer(numericDiscreteCols+stringCols))\n",
    "    \n",
    "    reg_all_cols = numericContinuosCols + [c+'_C' for c in reg_all_discrete_cols]\n",
    "\n",
    "    oh = list(onehot(reg_all_discrete_cols))\n",
    "    ar = [VectorAssembler(inputCols=reg_all_cols, outputCol=\"features\")]\n",
    "    \n",
    "    stages += oh+ar\n",
    "\n",
    "    #set the pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    #fit\n",
    "    model = pipeline.fit(df)\n",
    "\n",
    "    #select columns\n",
    "    columns = []\n",
    "    columns += [col(idCol).alias('id')] if idCol else []\n",
    "    columns += [col(labelCol).alias('label')] if labelCol else []\n",
    "    columns += ['features']\n",
    "\n",
    "    #transform\n",
    "    features_df = model.transform(df).select(*columns)\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|   Fare|Embarked|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|   7.25|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|71.2833|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|  7.925|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|   53.1|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|   8.05|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|28.963899873494455|    0|    0| 8.4583|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|51.8625|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1| 21.075|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|11.1333|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|30.0708|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|   16.7|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|  26.55|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|   8.05|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5| 31.275|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0| 7.8542|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|   16.0|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1| 29.125|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male| 33.00598190211949|    0|    0|   13.0|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|   18.0|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|25.220669460419217|    0|    0|  7.225|       C|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = engine.read('.etl.clean.train')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+-----+\n",
      "|    name|value|count|index|\n",
      "+--------+-----+-----+-----+\n",
      "|  Pclass|    3|  491|    0|\n",
      "|  Pclass|    1|  216|    1|\n",
      "|  Pclass|    2|  184|    2|\n",
      "|Embarked|    S|  646|    0|\n",
      "|Embarked|    C|  168|    1|\n",
      "|Embarked|    Q|   77|    2|\n",
      "|   Parch|    0|  678|    0|\n",
      "|   Parch|    1|  118|    1|\n",
      "|   Parch|    2|   80|    2|\n",
      "|   Parch|    3|    5|    3|\n",
      "|   Parch|    5|    5|    4|\n",
      "|   Parch|    4|    4|    5|\n",
      "|   Parch|    6|    1|    6|\n",
      "|   SibSp|    0|  608|    0|\n",
      "|   SibSp|    1|  209|    1|\n",
      "|   SibSp|    2|   28|    2|\n",
      "|   SibSp|    4|   18|    3|\n",
      "|   SibSp|    3|   16|    4|\n",
      "|   SibSp|    8|    7|    5|\n",
      "|   SibSp|    5|    5|    6|\n",
      "+--------+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lut = collect_lut(df, ['Pclass','SibSp','Parch']+['Sex', 'Embarked'])\n",
    "lut.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------------------------------------------------------+\n",
      "|id |label|features                                                        |\n",
      "+---+-----+----------------------------------------------------------------+\n",
      "|1  |0    |(19,[0,1,2,5,10,16,17],[22.0,7.25,1.0,1.0,1.0,1.0,1.0])         |\n",
      "|2  |1    |(19,[0,1,3,5,10,18],[38.0,71.2833,1.0,1.0,1.0,1.0])             |\n",
      "|3  |1    |(19,[0,1,2,4,10,17],[26.0,7.925,1.0,1.0,1.0,1.0])               |\n",
      "|4  |1    |(19,[0,1,3,5,10,17],[35.0,53.1,1.0,1.0,1.0,1.0])                |\n",
      "|5  |0    |(19,[0,1,2,4,10,16,17],[35.0,8.05,1.0,1.0,1.0,1.0,1.0])         |\n",
      "|6  |0    |(19,[0,1,2,4,10,16],[28.963899873494455,8.4583,1.0,1.0,1.0,1.0])|\n",
      "|7  |0    |(19,[0,1,3,4,10,16,17],[54.0,51.8625,1.0,1.0,1.0,1.0,1.0])      |\n",
      "|8  |0    |(19,[0,1,2,8,11,16,17],[2.0,21.075,1.0,1.0,1.0,1.0,1.0])        |\n",
      "|9  |1    |(19,[0,1,2,4,12,17],[27.0,11.1333,1.0,1.0,1.0,1.0])             |\n",
      "|10 |1    |(19,[0,1,5,10,18],[14.0,30.0708,1.0,1.0,1.0])                   |\n",
      "|11 |1    |(19,[0,1,2,5,11,17],[4.0,16.7,1.0,1.0,1.0,1.0])                 |\n",
      "|12 |1    |(19,[0,1,3,4,10,17],[58.0,26.55,1.0,1.0,1.0,1.0])               |\n",
      "|13 |0    |(19,[0,1,2,4,10,16,17],[20.0,8.05,1.0,1.0,1.0,1.0,1.0])         |\n",
      "|14 |0    |(19,[0,1,2,5,14,16,17],[39.0,31.275,1.0,1.0,1.0,1.0,1.0])       |\n",
      "|15 |0    |(19,[0,1,2,4,10,17],[14.0,7.8542,1.0,1.0,1.0,1.0])              |\n",
      "|16 |1    |(19,[0,1,4,10,17],[55.0,16.0,1.0,1.0,1.0])                      |\n",
      "|17 |0    |(19,[0,1,2,7,11,16],[2.0,29.125,1.0,1.0,1.0,1.0])               |\n",
      "|18 |1    |(19,[0,1,4,10,16,17],[33.00598190211949,13.0,1.0,1.0,1.0,1.0])  |\n",
      "|19 |0    |(19,[0,1,2,5,10,17],[31.0,18.0,1.0,1.0,1.0,1.0])                |\n",
      "|20 |1    |(19,[0,1,2,4,10,18],[25.220669460419217,7.225,1.0,1.0,1.0,1.0]) |\n",
      "+---+-----+----------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features = featurize(df, 'PassengerId', 'Survived', ['Age', 'Fare'], ['Pclass','SibSp','Parch'], ['Sex', 'Embarked'], lut)\n",
    "df_features.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.write(df_features,'train', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----------------+-----+-----+-------+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex|             Age|SibSp|Parch|   Fare|Embarked|\n",
      "+-----------+------+--------------------+------+----------------+-----+-----+-------+--------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|            34.5|    0|    0| 7.8292|       Q|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|            47.0|    1|    0|    7.0|       S|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|            62.0|    0|    0| 9.6875|       Q|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|            27.0|    0|    0| 8.6625|       S|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|            22.0|    1|    1|12.2875|       S|\n",
      "|        897|     3|Svensson, Mr. Joh...|  male|            14.0|    0|    0|  9.225|       S|\n",
      "|        898|     3|Connolly, Miss. Kate|female|            30.0|    0|    0| 7.6292|       Q|\n",
      "|        899|     2|Caldwell, Mr. Alb...|  male|            26.0|    1|    1|   29.0|       S|\n",
      "|        900|     3|Abrahim, Mrs. Jos...|female|            18.0|    0|    0| 7.2292|       C|\n",
      "|        901|     3|Davies, Mr. John ...|  male|            21.0|    2|    0|  24.15|       S|\n",
      "|        902|     3|    Ilieff, Mr. Ylio|  male|26.0066152304355|    0|    0| 7.8958|       S|\n",
      "|        903|     1|Jones, Mr. Charle...|  male|            46.0|    0|    0|   26.0|       S|\n",
      "|        904|     1|Snyder, Mrs. John...|female|            23.0|    1|    0|82.2667|       S|\n",
      "|        905|     2|Howard, Mr. Benjamin|  male|            63.0|    1|    0|   26.0|       S|\n",
      "|        906|     1|Chaffee, Mrs. Her...|female|            47.0|    1|    0| 61.175|       S|\n",
      "|        907|     2|del Carlo, Mrs. S...|female|            24.0|    1|    0|27.7208|       C|\n",
      "|        908|     2|   Keane, Mr. Daniel|  male|            35.0|    0|    0|  12.35|       Q|\n",
      "|        909|     3|   Assaf, Mr. Gerios|  male|            21.0|    0|    0|  7.225|       C|\n",
      "|        910|     3|Ilmakangas, Miss....|female|            27.0|    1|    0|  7.925|       S|\n",
      "|        911|     3|\"Assaf Khalil, Mr...|female|            45.0|    0|    0|  7.225|       C|\n",
      "+-----------+------+--------------------+------+----------------+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = engine.read('.etl.clean.test')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------------------------------------------------+\n",
      "|id |features                                                             |\n",
      "+---+---------------------------------------------------------------------+\n",
      "|892|(19,[0,1,2,4,10,16],[34.5,7.8292,1.0,1.0,1.0,1.0])                   |\n",
      "|893|(19,[0,1,2,5,10,17],[47.0,7.0,1.0,1.0,1.0,1.0])                      |\n",
      "|894|(19,[0,1,4,10,16],[62.0,9.6875,1.0,1.0,1.0])                         |\n",
      "|895|(19,[0,1,2,4,10,16,17],[27.0,8.6625,1.0,1.0,1.0,1.0,1.0])            |\n",
      "|896|(19,[0,1,2,5,11,17],[22.0,12.2875,1.0,1.0,1.0,1.0])                  |\n",
      "|897|(19,[0,1,2,4,10,16,17],[14.0,9.225,1.0,1.0,1.0,1.0,1.0])             |\n",
      "|898|(19,[0,1,2,4,10],[30.0,7.6292,1.0,1.0,1.0])                          |\n",
      "|899|(19,[0,1,5,11,16,17],[26.0,29.0,1.0,1.0,1.0,1.0])                    |\n",
      "|900|(19,[0,1,2,4,10,18],[18.0,7.2292,1.0,1.0,1.0,1.0])                   |\n",
      "|901|(19,[0,1,2,6,10,16,17],[21.0,24.15,1.0,1.0,1.0,1.0,1.0])             |\n",
      "|902|(19,[0,1,2,4,10,16,17],[26.0066152304355,7.8958,1.0,1.0,1.0,1.0,1.0])|\n",
      "|903|(19,[0,1,3,4,10,16,17],[46.0,26.0,1.0,1.0,1.0,1.0,1.0])              |\n",
      "|904|(19,[0,1,3,5,10,17],[23.0,82.2667,1.0,1.0,1.0,1.0])                  |\n",
      "|905|(19,[0,1,5,10,16,17],[63.0,26.0,1.0,1.0,1.0,1.0])                    |\n",
      "|906|(19,[0,1,3,5,10,17],[47.0,61.175,1.0,1.0,1.0,1.0])                   |\n",
      "|907|(19,[0,1,5,10,18],[24.0,27.7208,1.0,1.0,1.0])                        |\n",
      "|908|(19,[0,1,4,10,16],[35.0,12.35,1.0,1.0,1.0])                          |\n",
      "|909|(19,[0,1,2,4,10,16,18],[21.0,7.225,1.0,1.0,1.0,1.0,1.0])             |\n",
      "|910|(19,[0,1,2,5,10,17],[27.0,7.925,1.0,1.0,1.0,1.0])                    |\n",
      "|911|(19,[0,1,2,4,10,18],[45.0,7.225,1.0,1.0,1.0,1.0])                    |\n",
      "+---+---------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features = featurize(df, 'PassengerId', None, ['Age', 'Fare'], ['Pclass','SibSp','Parch'], ['Sex', 'Embarked'], lut)\n",
    "df_features.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.write(df_features,'test', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
