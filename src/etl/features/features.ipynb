{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b':2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datalabframework as dlf\n",
    "dlf.project.rootpath()\n",
    "dlf.project.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine = dlf.engines.get('spark')\n",
    "spark = engine.context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark:2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out name and version\n",
    "'{}:{}'.format(engine.info['context'], spark.sparkSession.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit, countDistinct\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "def describe_all(df):\n",
    "\n",
    "    spark = SQLContext(SparkContext.getOrCreate())\n",
    "\n",
    "    cols = ['summary'] + df.columns\n",
    "    df_nan  = df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).withColumn('summary', lit('nan')).toPandas()\n",
    "    df_null = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).withColumn('summary', lit('isnull')).toPandas()\n",
    "    df_type = pd.DataFrame(data=[['type']+[str(c.dataType)[:-4] for c in df.schema]], columns=['summary']+df.columns)\n",
    "    df_distinct =  df.select([countDistinct(c).alias(c) for c in df.columns]).withColumn('summary', lit('distinct')).toPandas()\n",
    "    d = pd.concat([df_nan, df_null, df_type, df_distinct, df.describe().toPandas()], sort='false').reset_index().drop('index', axis=1).astype(str)\n",
    "    return spark.createDataFrame(d[cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT\n",
    "import json\n",
    "\n",
    "from pyspark.ml import Estimator, Model\n",
    "from pyspark.ml.param.shared import *\n",
    "from pyspark.sql.functions import col, count\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "\n",
    "class HasLookupTable(Params):\n",
    "\n",
    "    lookup_table  = Param(Params._dummy(), \"lookup_table\", \"lookup_table\")   # it's a dictionary (string -> integer)\n",
    "    default_value = Param(Params._dummy(), \"default_value\", \"default_value\", typeConverter=TypeConverters.toInt) # it's an integer\n",
    "\n",
    "    def __init__(self):\n",
    "        super(HasLookupTable, self).__init__()\n",
    "\n",
    "    def setLookupTable(self, value):\n",
    "        return self._set(lookup_table=value)\n",
    "\n",
    "    def getLookupTable(self):\n",
    "        return self.getOrDefault(self.lookup_table)\n",
    "    \n",
    "    def setDefaultValue(self, value):\n",
    "        return self._set(default_value=value)\n",
    "\n",
    "    def getDefaultValue(self):\n",
    "        return self.getOrDefault(self.default_value)\n",
    "\n",
    "class LookupIndexer(Estimator, HasInputCol, HasPredictionCol):\n",
    "\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(LookupIndexer, self).__init__()\n",
    "        self.setInputCol(inputCol)\n",
    "        self.setPredictionCol(outputCol)\n",
    "\n",
    "    def _fit(self, dataset):\n",
    "        c = self.getInputCol()\n",
    "        \n",
    "        occurrences = dataset.groupBy(col(c)).agg(count(c).alias('count')).sort('count', ascending=False)\n",
    "        values = [str(x[c]) for x in occurrences.select(c).collect()]\n",
    "\n",
    "        lut = dict(zip(values,range(len(values))))\n",
    "        dvalue = 0  #if not found use the most frequent class\n",
    "        \n",
    "        return (LookupIndexerModel()\n",
    "            .setInputCol(c)\n",
    "            .setLookupTable(lut)\n",
    "            .setDefaultValue(dvalue)\n",
    "            .setPredictionCol(self.getPredictionCol()))\n",
    "\n",
    "class LookupIndexerModel(Model, HasInputCol, HasPredictionCol, HasLookupTable):\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        x = self.getInputCol()\n",
    "        y = self.getPredictionCol()\n",
    "        lut = self.getLookupTable()\n",
    "        dvalue = self.getDefaultValue()\n",
    "\n",
    "        # Use pandas_udf to define a Pandas UDF\n",
    "        @pandas_udf('integer', PandasUDFType.SCALAR)\n",
    "        def encode_colum(v):\n",
    "            r = v.apply(lambda x: lut.get(str(x),dvalue))\n",
    "            return r\n",
    "\n",
    "        return dataset.withColumn(y, encode_colum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT \n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler\n",
    "\n",
    "def featurize(numericContinuosCols=[], numericDiscreteCols=[], stringCols=[]):\n",
    "    def lookup_stages(features):\n",
    "        for c in features:\n",
    "            yield LookupIndexer(inputCol=c, outputCol=c+'_I')    \n",
    "\n",
    "    def onehot_stages(features):\n",
    "        for c in features:\n",
    "            yield OneHotEncoder(inputCol=c, outputCol=c+'_C')\n",
    "\n",
    "    reg_all_discrete_cols = [c+'_I' for c in numericDiscreteCols+stringCols]\n",
    "    reg_all_cols = numericContinuosCols + [c+'_C' for c in reg_all_discrete_cols]\n",
    "\n",
    "    stages  = []\n",
    "    stages += list(lookup_stages(numericDiscreteCols+stringCols))\n",
    "    stages += list(onehot_stages(reg_all_discrete_cols))\n",
    "    stages += [VectorAssembler(inputCols=reg_all_cols, outputCol=\"features\")]\n",
    "    \n",
    "    return Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|   Fare|Embarked|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------+--------+\n",
      "|        246|       0|     1|Minahan, Dr. Will...|  male|              44.0|    2|    0|   90.0|       Q|\n",
      "|        346|       1|     2|\"Brown, Miss. Ame...|female|              24.0|    0|    0|   13.0|       S|\n",
      "|        360|       1|     3|\"Mockler, Miss. H...|female| 26.24842701587761|    0|    0| 7.8792|       Q|\n",
      "|        367|       1|     1|Warren, Mrs. Fran...|female|              60.0|    1|    0|  75.25|       C|\n",
      "|        476|       0|     1|Clifford, Mr. Geo...|  male| 42.21393334298665|    0|    0|   52.0|       S|\n",
      "|        539|       0|     3|Risien, Mr. Samue...|  male|27.844465003907715|    0|    0|   14.5|       S|\n",
      "|        599|       0|     3|   Boulos, Mr. Hanna|  male|26.552053955241124|    0|    0|  7.225|       C|\n",
      "|        725|       1|     1|Chambers, Mr. Nor...|  male|              27.0|    1|    0|   53.1|       S|\n",
      "|        855|       0|     2|Carter, Mrs. Erne...|female|              44.0|    1|    0|   26.0|       S|\n",
      "|        861|       0|     3|Hansen, Mr. Claus...|  male|              41.0|    2|    0|14.1083|       S|\n",
      "|        114|       0|     3|Jussila, Miss. Ka...|female|              20.0|    1|    0|  9.825|       S|\n",
      "|        173|       1|     3|Johnson, Miss. El...|female|               1.0|    1|    1|11.1333|       S|\n",
      "|        220|       0|     2|  Harris, Mr. Walter|  male|              30.0|    0|    0|   10.5|       S|\n",
      "|        278|       0|     2|\"Parkes, Mr. Fran...|  male| 32.33447606807707|    0|    0|    0.0|       S|\n",
      "|        301|       1|     3|\"Kelly, Miss. Ann...|female| 26.24842701587761|    0|    0|   7.75|       Q|\n",
      "|        494|       0|     1|Artagaveytia, Mr....|  male|              71.0|    0|    0|49.5042|       C|\n",
      "|        669|       0|     3|     Cook, Mr. Jacob|  male|              43.0|    0|    0|   8.05|       S|\n",
      "|        713|       1|     1|Taylor, Mr. Elmer...|  male|              48.0|    1|    0|   52.0|       S|\n",
      "|        810|       1|     1|Chambers, Mrs. No...|female|              33.0|    1|    0|   53.1|       S|\n",
      "|        813|       0|     2|Slemen, Mr. Richa...|  male|              35.0|    0|    0|   10.5|       S|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = engine.read('.etl.clean.train')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = featurize(['Age', 'Fare'], ['Pclass','SibSp','Parch'], ['Sex', 'Embarked'])\n",
    "m = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------------------------------------------------------------+\n",
      "|id |label|features                                                              |\n",
      "+---+-----+----------------------------------------------------------------------+\n",
      "|246|0    |(19,[0,1,3,6,10,16],[44.0,90.0,1.0,1.0,1.0,1.0])                      |\n",
      "|346|1    |(19,[0,1,4,10,17],[24.0,13.0,1.0,1.0,1.0])                            |\n",
      "|360|1    |(19,[0,1,2,4,10],[26.24842701587761,7.8792,1.0,1.0,1.0])              |\n",
      "|367|1    |(19,[0,1,3,5,10,18],[60.0,75.25,1.0,1.0,1.0,1.0])                     |\n",
      "|476|0    |(19,[0,1,3,4,10,16,17],[42.21393334298665,52.0,1.0,1.0,1.0,1.0,1.0])  |\n",
      "|539|0    |(19,[0,1,2,4,10,16,17],[27.844465003907715,14.5,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|599|0    |(19,[0,1,2,4,10,16,18],[26.552053955241124,7.225,1.0,1.0,1.0,1.0,1.0])|\n",
      "|725|1    |(19,[0,1,3,5,10,16,17],[27.0,53.1,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|855|0    |(19,[0,1,5,10,17],[44.0,26.0,1.0,1.0,1.0])                            |\n",
      "|861|0    |(19,[0,1,2,6,10,16,17],[41.0,14.1083,1.0,1.0,1.0,1.0,1.0])            |\n",
      "|114|0    |(19,[0,1,2,5,10,17],[20.0,9.825,1.0,1.0,1.0,1.0])                     |\n",
      "|173|1    |(19,[0,1,2,5,11,17],[1.0,11.1333,1.0,1.0,1.0,1.0])                    |\n",
      "|220|0    |(19,[0,1,4,10,16,17],[30.0,10.5,1.0,1.0,1.0,1.0])                     |\n",
      "|278|0    |(19,[0,4,10,16,17],[32.33447606807707,1.0,1.0,1.0,1.0])               |\n",
      "|301|1    |(19,[0,1,2,4,10],[26.24842701587761,7.75,1.0,1.0,1.0])                |\n",
      "|494|0    |(19,[0,1,3,4,10,16,18],[71.0,49.5042,1.0,1.0,1.0,1.0,1.0])            |\n",
      "|669|0    |(19,[0,1,2,4,10,16,17],[43.0,8.05,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|713|1    |(19,[0,1,3,5,10,16,17],[48.0,52.0,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|810|1    |(19,[0,1,3,5,10,17],[33.0,53.1,1.0,1.0,1.0,1.0])                      |\n",
      "|813|0    |(19,[0,1,4,10,16,17],[35.0,10.5,1.0,1.0,1.0,1.0])                     |\n",
      "+---+-----+----------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features = m.transform(df).select(col('PassengerId').alias('id'), col('Survived').alias('label'), col('features'))\n",
    "df_features.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.write(df_features,'train', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+------------------+-----+-----+--------+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex|               Age|SibSp|Parch|    Fare|Embarked|\n",
      "+-----------+------+--------------------+------+------------------+-----+-----+--------+--------+\n",
      "|        911|     3|\"Assaf Khalil, Mr...|female|              45.0|    0|    0|   7.225|       C|\n",
      "|        933|     1|Franklin, Mr. Tho...|  male| 42.21393334298665|    0|    0|   26.55|       S|\n",
      "|       1042|     1|Earnshaw, Mrs. Bo...|female|              23.0|    0|    1| 83.1583|       C|\n",
      "|       1131|     1|Douglas, Mrs. Wal...|female|              48.0|    1|    0| 106.425|       C|\n",
      "|       1140|     2|Hold, Mrs. Stephe...|female|              29.0|    1|    0|    26.0|       S|\n",
      "|       1185|     1|Dodge, Dr. Washin...|  male|              53.0|    1|    1| 81.8583|       S|\n",
      "|       1257|     3|Sage, Mrs. John (...|female|22.789618277529406|    1|    9|   69.55|       S|\n",
      "|       1308|     3| Ware, Mr. Frederick|  male|27.844465003907715|    0|    0|    8.05|       S|\n",
      "|       1041|     2|Lahtinen, Rev. Wi...|  male|              30.0|    1|    1|    26.0|       S|\n",
      "|       1075|     3|   Lane, Mr. Patrick|  male|27.844465003907715|    0|    0|    7.75|       Q|\n",
      "|       1076|     1|Douglas, Mrs. Fre...|female|              27.0|    1|    1|247.5208|       C|\n",
      "|       1111|     3|Thomson, Mr. Alex...|  male|27.844465003907715|    0|    0|    8.05|       S|\n",
      "|       1116|     1|Candee, Mrs. Edwa...|female|              53.0|    0|    0| 27.4458|       C|\n",
      "|       1287|     1|Smith, Mrs. Lucie...|female|              18.0|    1|    0|    60.0|       S|\n",
      "|        925|     3|\"Johnston, Mrs. A...|female|15.738835473964237|    1|    2|   23.45|       S|\n",
      "|        972|     3|Boulos, Master. Akar|  male|               6.0|    1|    1| 15.2458|       C|\n",
      "|        998|     3| Buckley, Mr. Daniel|  male|              21.0|    0|    0|  7.8208|       Q|\n",
      "|       1062|     3|  Lithman, Mr. Simon|  male|27.844465003907715|    0|    0|    7.55|       S|\n",
      "|       1082|     2|Angle, Mr. William A|  male|              34.0|    1|    0|    26.0|       S|\n",
      "|       1218|     2|Becker, Miss. Rut...|female|              12.0|    2|    1|    39.0|       S|\n",
      "+-----------+------+--------------------+------+------------------+-----+-----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = engine.read('.etl.clean.test')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------------------------------------------+\n",
      "|id  |features                                                             |\n",
      "+----+---------------------------------------------------------------------+\n",
      "|911 |(19,[0,1,2,4,10,18],[45.0,7.225,1.0,1.0,1.0,1.0])                    |\n",
      "|933 |(19,[0,1,3,4,10,16,17],[42.21393334298665,26.55,1.0,1.0,1.0,1.0,1.0])|\n",
      "|1042|(19,[0,1,3,4,11,18],[23.0,83.1583,1.0,1.0,1.0,1.0])                  |\n",
      "|1131|(19,[0,1,3,5,10,18],[48.0,106.425,1.0,1.0,1.0,1.0])                  |\n",
      "|1140|(19,[0,1,5,10,17],[29.0,26.0,1.0,1.0,1.0])                           |\n",
      "|1185|(19,[0,1,3,5,11,16,17],[53.0,81.8583,1.0,1.0,1.0,1.0,1.0])           |\n",
      "|1257|(19,[0,1,2,5,10,17],[22.789618277529406,69.55,1.0,1.0,1.0,1.0])      |\n",
      "|1308|(19,[0,1,2,4,10,16,17],[27.844465003907715,8.05,1.0,1.0,1.0,1.0,1.0])|\n",
      "|1041|(19,[0,1,5,11,16,17],[30.0,26.0,1.0,1.0,1.0,1.0])                    |\n",
      "|1075|(19,[0,1,2,4,10,16],[27.844465003907715,7.75,1.0,1.0,1.0,1.0])       |\n",
      "|1076|(19,[0,1,3,5,11,18],[27.0,247.5208,1.0,1.0,1.0,1.0])                 |\n",
      "|1111|(19,[0,1,2,4,10,16,17],[27.844465003907715,8.05,1.0,1.0,1.0,1.0,1.0])|\n",
      "|1116|(19,[0,1,3,4,10,18],[53.0,27.4458,1.0,1.0,1.0,1.0])                  |\n",
      "|1287|(19,[0,1,3,5,10,17],[18.0,60.0,1.0,1.0,1.0,1.0])                     |\n",
      "|925 |(19,[0,1,2,5,12,17],[15.738835473964237,23.45,1.0,1.0,1.0,1.0])      |\n",
      "|972 |(19,[0,1,2,5,11,16,18],[6.0,15.2458,1.0,1.0,1.0,1.0,1.0])            |\n",
      "|998 |(19,[0,1,2,4,10,16],[21.0,7.8208,1.0,1.0,1.0,1.0])                   |\n",
      "|1062|(19,[0,1,2,4,10,16,17],[27.844465003907715,7.55,1.0,1.0,1.0,1.0,1.0])|\n",
      "|1082|(19,[0,1,5,10,16,17],[34.0,26.0,1.0,1.0,1.0,1.0])                    |\n",
      "|1218|(19,[0,1,6,11,17],[12.0,39.0,1.0,1.0,1.0])                           |\n",
      "+----+---------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features = m.transform(df).select(col('PassengerId').alias('id'), col('features'))\n",
    "df_features.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.write(df_features,'test', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
